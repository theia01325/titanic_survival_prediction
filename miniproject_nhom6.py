# -*- coding: utf-8 -*-
"""MiniProject_Nhom6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13mgKomK0lERIC4eyEt48butefwK7u3az

#**TÃŠN Äá»€ TÃ€I: DieTanic**
**NHÃ“M 6**

**THÃ€NH VIÃŠN:**
- 1. Há» tÃªn: Nguyá»…n Äá»— KhÃ¡nh Ngá»c - MSSV: 23280008
- 2. Há» tÃªn: ThÃ¡i Ngá»c Thanh Mai - MSSV: 23280018
- 3. Há» tÃªn: Äáº·ng Trá»ng Báº£o Thi - MSSV: 23280025
- 4. Há» tÃªn: Nguyá»…n Ngá»c Minh - MSSV: 23280029
- 5. Há» tÃªn: Trá»‹nh Quá»‘c Tháº¯ng - MSSV: 23280009
- 6. Há» tÃªn: Nguyá»…n Trang Thanh TrÃºc - MSSV: 23280011

# ğŸŸ¢ 1. Problem Definition (XÃ¡c Ä‘á»‹nh bÃ i toÃ¡n)

Vá»¥ chÃ¬m tÃ u Titanic lÃ  má»™t trong nhá»¯ng vá»¥ chÃ¬m tÃ u tháº£m khá»‘c nháº¥t trong lá»‹ch sá»­. VÃ o ngÃ y 15 thÃ¡ng 4 nÄƒm 1912, trong chuyáº¿n hÃ nh trÃ¬nh vÆ°á»£t Äáº¡i TÃ¢y DÆ°Æ¡ng Ä‘áº§u tiÃªn cá»§a tÃ u, Titanic Ä‘Ã£ chÃ¬m sau khi va cháº¡m vá»›i má»™t táº£ng bÄƒng, khiáº¿n 1502 trÃªn 2224 hÃ nh khÃ¡ch vÃ  thá»§y thá»§ tÃ u thiá»‡t máº¡ng. ÄÃ¢y lÃ  lÃ½ do vÃ¬ sao Ä‘á» tÃ i tÃªn lÃ  DieTanic (Die + Titanic) vÃ  táº­p dataset nhÃ³m em sá»­ dá»¥ng lÃ  táº­p dataset Titanic ná»•i tiáº¿ng trong lÄ©nh vá»±c khoa há»c dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch.

* LÄ©nh vá»±c: XÃ£ há»™i, dá»± Ä‘oÃ¡n rá»§i ro.
* Loáº¡i bÃ i toÃ¡n: Classification (phÃ¢n loáº¡i).
* Má»¥c tiÃªu: Dá»± Ä‘oÃ¡n hÃ nh khÃ¡ch trÃªn chuyáº¿n tÃ u Titanic cÃ³ kháº£ nÄƒng sá»‘ng sÃ³t hay khÃ´ng.

**Cá»¥ thá»ƒ**: XÃ¡c Ä‘á»‹nh
- Problem: DÃ¡n nhÃ£n hÃ nh khÃ¡ch lÃ  sá»‘ng sÃ³t hay khÃ´ng (0 = KhÃ´ng, 1 = CÃ³)
- Input: CÃ¡c Ä‘áº·c tÃ­nh nhÆ° giá»›i tÃ­nh, háº¡ng vÃ© tÃ u, tuá»•i, cáº£ng xuáº¥t phÃ¡t,... cá»§a hÃ nh khÃ¡ch.
- Output: Biáº¿n *Survived* Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÃ nh khÃ¡ch sá»‘ng sÃ³t hay khÃ´ng.

# ğŸŸ¢ 2. Data Acquisition (Thu tháº­p dá»¯ liá»‡u)

###Nguá»“n dá»¯ liá»‡u

Titanic - Machine Learning from Disaster. Kaggle. Truy cáº­p táº¡i: https://www.kaggle.com/competitions/titanic

Trong giá»›i háº¡n cá»§a dá»± Ã¡n, nhÃ³m táº­p trung xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»±a trÃªn bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n (train.csv), khÃ´ng sá»­ dá»¥ng dá»¯ liá»‡u test.csv vÃ  gender_submission.csv.

###Äá»c dá»¯ liá»‡u
"""

# Import libary
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Install libary
!pip install gdown

# Download data from google drive
import gdown
file_id = "1RKB2Il6Sq04wF8clyJQi0PPGL8OYnSPP"
train = "train.csv"
gdown.download(f"https://drive.google.com/uc?id={file_id}", train, quiet=False)

df = pd.read_csv("train.csv")
df.head()

df.info()

"""###Data Description (MÃ´ táº£ dá»¯ liá»‡u)

1. **PassengerId**: MÃ£ sá»‘ cá»§a hÃ nh khÃ¡ch.
2. **Survived**: Biáº¿n target Ä‘á»ƒ classification.
3. **Pclass**: Háº¡ng vÃ©. (1 = 1st = Upper, 2 = 2nd = Middle, 3 = 3rd = Lower).
4. **Name**: TÃªn hÃ nh khÃ¡ch.
5. **Sex**: Giá»›i tÃ­nh. ('male', 'female')
6. **Age**: Tuá»•i. (Tuá»•i lÃ  phÃ¢n sá»‘ náº¿u nhá» hÆ¡n 1. Náº¿u tuá»•i Ä‘Æ°á»£c Æ°á»›c tÃ­nh, pháº£i á»Ÿ dáº¡ng xx.5)
7. **SibSp**: Sá»‘ anh chá»‹ em hoáº·c vá»£ chá»“ng trÃªn tÃ u Titanic. (bao gá»“m anh, chá»‹, em ruá»™t hoáº·c anh chá»‹ em káº¿, khÃ´ng tÃ­nh hÃ´n phu, hÃ´n thÃª, tÃ¬nh nhÃ¢n)
8. **Parch**: Sá»‘ cha máº¹ hoáº·c con ruá»™t hoáº·c con káº¿ cÃ³ trÃªn tÃ u Titanic (khÃ´ng tÃ­nh vÃº nuÃ´i).
9. **Ticket**: MÃ£ sá»‘ vÃ©.
10. **Fare**: GiÃ¡ vÃ© cá»§a hÃ nh khÃ¡ch.
11. **Cabin**: Sá»‘ cá»§a cabin.
12. **Embarked**: Cáº£ng xuáº¥t phÃ¡t.  (HÃ nh khÃ¡ch lÃªn tá»« cáº£ng nÃ o, C = Cherbourg, Q = Queenstown, S = Southampton)
"""

df_copy = df.copy()

"""# ğŸŸ¢ 3. Data Exploration (KhÃ¡m phÃ¡ dá»¯ liá»‡u - EDA)"""

# Chá»n categorical features
categorical_data=df.select_dtypes(include= 'object')
categorical_features=categorical_data.columns.tolist()

print(f'There are {len(categorical_features)} categorical features:', '\n')
print(categorical_features)

# Chá»n numerical features
numerical_data = df.select_dtypes(include='number')
numerical_features=numerical_data.columns.tolist()

print(f'There are {len(numerical_features)} numerical features:', '\n')
print(numerical_features)

"""## 3.1. Categorical Features"""

# Number of unique values in each categorical feature
unique_counts=categorical_data.nunique()

for index,i in enumerate(range(len(categorical_features)),start=1):
    print(index,"{a} has {b} unique values".format(a=categorical_features[i],b=unique_counts[i]))

categorical_data.isnull().sum()

categorical_cols = [col for col in categorical_data.select_dtypes(include=['object']).columns if categorical_data[col].nunique() <= 20]
print("Identify categorical columns with 20 or fewer unique valuesc:", categorical_cols)

for col in categorical_cols:
    print(f"ğŸ”¹ Column: {col}")
    print(categorical_data[col].value_counts(dropna=False))
    print("-" * 50)

"""### Cá»™t *Name*"""

categorical_data['Name']

"""**Remarks**: tÃªn cá»§a khÃ¡ch hÃ ng cÃ³ chá»©a cÃ¡c danh xÆ°ng nhÆ° Mr vÃ  Ms, cÃ³ thá»ƒ giÃºp rÃºt ra thÃ´ng tin vá» giá»›i tÃ­nh vÃ  cÃ³ thá»ƒ suy Ä‘oÃ¡n Ä‘á»™ tuá»•i.

**Next Action**: táº¡o cá»™t má»›i *Honorific* chá»©a danh xÆ°ng Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« cá»™t *Name*.
"""

df_copy['Honorific'] = 0
for i in df_copy:
    df_copy['Honorific'] = df_copy.Name.str.extract('([A-Za-z]+)\.')

df_copy['Honorific']

df_copy['Honorific'].value_counts()

# Chá»‰nh sá»­a cÃ¡c giÃ¡ trá»‹ viáº¿t sai trong cá»™t Honorific
df_copy['Honorific'] = df_copy['Honorific'].replace(
    ['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],
    ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'])

df_copy['Honorific'].value_counts()

"""**Remarks**:


*   Mr: dÃ¹ng Ä‘á»ƒ gá»i nam giá»›i trÆ°á»Ÿng thÃ nh, khÃ´ng phÃ¢n biá»‡t tÃ¬nh tráº¡ng hÃ´n nhÃ¢n.
*   Miss: dÃ¹ng Ä‘á»ƒ gá»i ná»¯ giá»›i chÆ°a káº¿t hÃ´n, thÆ°á»ng lÃ  phá»¥ ná»¯ tráº» hoáº·c tráº» em gÃ¡i.
*   Mrs: dÃ¹ng Ä‘á»ƒ gá»i phá»¥ ná»¯ Ä‘Ã£ káº¿t hÃ´n.
*   Master: dÃ¹ng Ä‘á»ƒ gá»i tráº» em trai hoáº·c nam thiáº¿u niÃªn chÆ°a trÆ°á»Ÿng thÃ nh.
*   Other: cÃ¡c danh xÆ°ng Ã­t gáº·p khÃ¡c (Jonkheer - quÃ½ tá»™c, Col - Äáº¡i tÃ¡ vÃ  Rev - linh má»¥c)

### Cá»™t *Sex*
"""

categorical_data['Sex'].value_counts().sort_index().plot(kind='bar', rot=0, xlabel='Sex',ylabel='count')

"""**Remarks**: Sá»‘ nam giá»›i trÃªn tÃ u nhiá»u gáº§n gáº¥p Ä‘Ã´i ná»¯ giá»›i."""

# Heatmap thá»ƒ hiá»‡n tÃ­nh tÆ°Æ¡ng quan giá»¯a Sex vÃ  biáº¿n target (Survived)
pivot_table = pd.crosstab(df_copy['Sex'], df_copy['Survived'])
pivot_table
plt.figure(figsize=(6,4))
sns.heatmap(pivot_table, annot=True, fmt='d', cmap='YlGnBu', linewidths=.5)

plt.title('Heatmap of Counts by Sex and Survived')
plt.xlabel('Survived')
plt.ylabel('Sex')
plt.tight_layout()
plt.show()

"""**Remarks**: Máº·c dÃ¹ nam giá»›i chiáº¿m Ä‘a sá»‘ vá» sá»‘ lÆ°á»£ng, nhÆ°ng tá»· lá»‡ sá»‘ng sÃ³t láº¡i hoÃ n toÃ n ngÆ°á»£c láº¡i: sá»‘ ná»¯ giá»›i sá»‘ng sÃ³t nhiá»u gáº¥p hÆ¡n hai láº§n sá»‘ nam giá»›i sá»‘ng sÃ³t, trong khi sá»‘ nam tá»­ vong cÅ©ng lá»›n hÆ¡n ráº¥t nhiá»u so vá»›i ná»¯. Äiá»u nÃ y cho tháº¥y giá»›i tÃ­nh lÃ  má»™t yáº¿u tá»‘ quan trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t, cá»¥ thá»ƒ lÃ  ná»¯ giá»›i cÃ³ kháº£ nÄƒng Ä‘Æ°á»£c Æ°u tiÃªn cá»©u há»™ hÆ¡n nam giá»›i.

### Cá»™t *Ticket*
"""

categorical_data['Ticket']

"""**Remarks**: tÆ°Æ¡ng tá»± vá»›i cá»™t *Name*, cá»™t nÃ y cÅ©ng khÃ´ng mang thÃ´ng tin há»¯u Ã­ch cho quÃ¡ trÃ¬nh mÃ´ hÃ¬nh hoÃ¡ nÃªn cÃ³ thá»ƒ loáº¡i bá» khi xÃ¢y dá»±ng mÃ´ hÃ¬nh.

### Cá»™t *Cabin*
"""

categorical_data['Cabin']

# In nhá»¯ng hÃ ng cÃ³ cá»™t Cabin null
df[df['Cabin'].isnull()]

"""**Remarks**: cá»™t nÃ y cÃ³ quÃ¡ nhiá»u dá»¯ liá»‡u khuyáº¿t (687/891) vÃ  thÃ´ng tin sá»‘ cabin cÅ©ng khÃ´ng há»— trá»£ mÃ´ hÃ¬nh hoÃ¡, nÃªn cÃ³ thá»ƒ loáº¡i bá» khi xÃ¢y dá»±ng mÃ´ hÃ¬nh.

### Cá»™t *Embarked*
"""

categorical_data['Embarked'].value_counts().sort_index().plot(kind='bar', rot=0, xlabel='Embarked',ylabel='count')

"""**Remarks**: pháº§n lá»›n hÃ nh khÃ¡ch xuáº¥t phÃ¡t tá»« cáº£ng S.

**Next Action**: thay tháº¿ giÃ¡ trá»‹ khuyáº¿t cá»§a cá»™t *Embarked* báº±ng mode ('S')
"""

# Kiá»ƒm tra tÃ­nh tÆ°Æ¡ng quan cá»§a cá»™t Embarked vÃ  biáº¿n target
sns.catplot(x='Embarked', y='Survived', data=df_copy, kind='bar')
fig=plt.gcf()
fig.set_size_inches(5,3)
plt.show()

"""**Remarks**: tá»· lá»‡ sá»‘ng sÃ³t cá»§a nhá»¯ng hÃ nh khÃ¡ch á»Ÿ cáº£ng C lÃ  cao nháº¥t vá»›i khoáº£ng 55%, tháº¥p nháº¥t á»Ÿ cáº£ng S vá»›i khoáº£ng hÆ¡n 30%. Äiá»u nÃ y cho tháº¥y cáº£ng xuáº¥t phÃ¡t cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t."""

f,ax=plt.subplots(1,2,figsize=(20,15))
sns.countplot(x='Embarked',hue='Sex',data=df_copy,ax=ax[0])
ax[0].set_title('Male-Female Split for Embarked')
sns.countplot(x='Embarked',hue='Pclass',data=df_copy,ax=ax[1])
ax[1].set_title('Embarked vs Pclass')
plt.subplots_adjust(wspace=0.2,hspace=0.5)
plt.show()

"""**Remarks**:


*   á» cáº£ 3 cáº£ng, sá»‘ nam giá»›i Ä‘á»u nhiá»u hÆ¡n ná»¯ giá»›i vÃ  sá»‘ hÃ nh khÃ¡ch cÃ³ háº¡ng vÃ© 3 Ä‘á»u nhiá»u nháº¥t.
*   Háº§u nhÆ° má»i hÃ nh khÃ¡ch xuáº¥t phÃ¡t tá»« cáº£ng Q Ä‘á»u Ä‘i háº¡ng vÃ© 3.
*   Sá»‘ ngÆ°á»i Ä‘i háº¡ng vÃ© 1 vÃ  2 xuáº¥t phÃ¡t tá»« cáº£ng S lÃ  nhiá»u nháº¥t.

## 3.2. Numerical Features
"""

# This table show basic statistics like mean, quantiles, Standard deviation about each numerical features
numerical_data.describe().T

numerical_data.isnull().sum()

"""### Cá»™t *Survived* (Target)"""

# Count values in Survived
df_copy['Survived'].value_counts()

sns.countplot(x='Survived', data=df_copy)
plt.title('Survival Count')
plt.xlabel('Survived (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

"""**Remarks**: Sá»‘ ngÆ°á»i khÃ´ng sá»‘ng sÃ³t cao hÆ¡n gáº¥p rÆ°á»¡i sá»‘ ngÆ°á»i sá»‘ng sÃ³t

### Cá»™t *PassengerID*
"""

# Kiá»ƒm tra cá»™t cÃ³ missing values khÃ´ng
df_copy['PassengerId'].isnull().sum()

"""**Remark:** Cá»™t nÃ y khÃ´ng mang thÃ´ng tin há»¯u Ã­ch cho quÃ¡ trÃ¬nh mÃ´ hÃ¬nh hÃ³a, tuy nhiÃªn cÃ³ thá»ƒ giá»¯ láº¡i Ä‘á»ƒ cÃ³ thá»ƒ Ä‘á»‘i chiáº¿u hoáº·c join káº¿t quáº£ vá» sau.

### Cá»™t *PClass*
"""

df_copy['Pclass'].value_counts()

"""*PClass* lÃ  biáº¿n thá»© báº­c (ordinal feature)."""

# Barplot for PClass
sns.countplot(x='Pclass', data=df_copy)
plt.title('Pclass Count')
plt.xlabel('Pclass')
plt.ylabel('Count')
plt.show()

"""**Remarks:** Sá»‘ khÃ¡ch á»Ÿ háº¡ng vÃ© 1 (Upper) vÃ  háº¡ng vÃ© 2 (Middle) xáº¥p xá»‰ nhau trong khi sá»‘ hÃ nh khÃ¡ch á»Ÿ háº¡ng vÃ© 3 (Lower) chiáº¿m Æ°u tháº¿ vá»›i sá»‘ lÆ°á»£ng nhiá»u hÆ¡n cáº£ tá»•ng cá»§a hai háº¡ng cÃ²n láº¡i."""

# Heatmap thá»ƒ hiá»‡n tÃ­nh tÆ°Æ¡ng quan giá»¯a PClass vÃ  biáº¿n target (Survived)
pivot_table = pd.crosstab(df_copy['Pclass'], df_copy['Survived'])
pivot_table
plt.figure(figsize=(6,4))
sns.heatmap(pivot_table, annot=True, fmt='d', cmap='YlGnBu', linewidths=.5)

plt.title('Heatmap of Counts by Pclass and Survived')
plt.xlabel('Survived')
plt.ylabel('Pclass')
plt.tight_layout()
plt.show()

sns.catplot(x='Pclass', y='Survived', data=df_copy, kind='bar')
fig=plt.gcf()
fig.set_size_inches(5,3)
plt.show()

"""**Remarks**:
*   Tá»‰ lá»‡ sá»‘ng sÃ³t á»Ÿ háº¡ng vÃ© 1 lÃ  cao nháº¥t vá»›i khoáº£ng 62%, tiáº¿p theo Ä‘Ã³ lÃ  háº¡ng vÃ©  2 vá»›i khoáº£ng 48% vÃ  cuá»‘i cÃ¹ng lÃ  háº¡ng 3 vá»›i khoáº£ng 25%. Äiá»u nÃ y cho tháº¥y háº¡ng vÃ© lÃ  má»™t yáº¿u tá»‘ quan trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t, háº¡ng vÃ© cÃ ng cao cáº¥p thÃ¬ cÆ¡ há»™i sá»‘ng sÃ³t cÃ ng cao.
*   Sá»‘ ngÆ°á»i cháº¿t á»Ÿ háº¡ng vÃ© 3 cá»±c ká»³ lá»›n, Ä‘iá»u nÃ y Ä‘áº¿n tá»« sá»‘ lÆ°á»£ng hÃ nh khÃ¡ch háº¡ng 3 ráº¥t lá»›n, dáº«n Ä‘áº¿n thiá»‡t háº¡i nhÃ¢n máº¡ng cao.
"""

# Kiá»ƒm tra tÃ­nh tÆ°Æ¡ng quan giá»¯a Pclass, Sex vÃ  Survived
sns.catplot(x='Pclass', y='Survived', hue='Sex', data=df_copy, kind='bar')
plt.show()

"""**Remarks**:
*   DÃ¹ á»Ÿ háº¡ng vÃ© nÃ o, phá»¥ ná»¯ cÅ©ng cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n rÃµ rá»‡t so vá»›i nam giá»›i. Tuy nhiÃªn, náº¿u thuá»™c háº¡ng vÃ© 3 thÃ¬ kháº£ nÄƒng sá»‘ng sÃ³t cá»§a há» cÅ©ng bá»‹ giáº£m Ä‘Ã¡ng ká»ƒ, tá»« hÆ¡n 90% á»Ÿ háº¡ng vÃ© 1 vÃ  2 xuá»‘ng khoáº£ng 50%.
*   TÃ¡c Ä‘á»™ng kÃ©p cá»§a *Sex* vÃ  *Pclass*: náº¿u lÃ  ná»¯, thÃ¬ cÃ³ lá»£i tháº¿ sá»‘ng sÃ³t; náº¿u lÃ  ná»¯ cÃ³ háº¡ng vÃ© cao, gáº§n nhÆ° cháº¯c cháº¯n Ä‘Æ°á»£c cá»©u; ngÆ°á»£c láº¡i, náº¿u lÃ  nam á»Ÿ háº¡ng vÃ© tháº¥p, kháº£ nÄƒng sá»‘ng sÃ³t lÃ  tháº¥p nháº¥t vá»›i dÆ°á»›i 20%.

### Cá»™t *Age*
"""

numerical_data['Age']

"""Ta cÃ³ thá»ƒ xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ khuyáº¿t trong cá»™t *Age* dá»±a vÃ o cá»™t *Honorific*."""

# TÃ­nh giÃ¡ trá»‹ tuá»•i trung bÃ¬nh cá»§a tá»«ng nhÃ³m danh xÆ°ng
df_copy.groupby('Honorific')['Age'].mean()

"""**Next Action**: thay tháº¿ cÃ¡c giÃ¡ trá»‹ khuyáº¿t trong cá»™t Age báº±ng giÃ¡ trá»‹ tuá»•i trung bÃ¬nh cá»§a tá»«ng nhÃ³m danh xÆ°ng."""

# Kiá»ƒm tra tÃ­nh tÆ°Æ¡ng quan giá»¯a biáº¿n Age vÃ  biáº¿n Survived
f,ax=plt.subplots(1,2,figsize=(20,10))
df_copy[df_copy['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')
ax[0].set_title('Survived= 0')
x1=list(range(0,85,5))
ax[0].set_xticks(x1)
df_copy[df_copy['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')
ax[1].set_title('Survived= 1')
x2=list(range(0,85,5))
ax[1].set_xticks(x2)
plt.show()

"""**Remarks**:

*   Tráº» em tá»« 0 - 10 tuá»•i cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n rÃµ rá»‡t.
*   NgÆ°á»i trÃªn 60 tuá»•i cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t tháº¥p.

**Next Action**: NÃªn Ã¡p dá»¥ng ká»¹ thuáº­t binning Ä‘á»ƒ phÃ¢n nhÃ³m tuá»•i, tá»« Ä‘Ã³ dá»… dÃ ng phÃ¢n tÃ­ch vÃ  mÃ´ hÃ¬nh hÃ³a áº£nh hÆ°á»Ÿng cá»§a tá»«ng nhÃ³m tuá»•i Ä‘áº¿n tá»· lá»‡ sá»‘ng sÃ³t.

### Cá»™t *SipSb*
"""

df_copy['SibSp'].value_counts()

# Plot for Sibsp
sns.countplot(x='SibSp', data=df_copy)
plt.title('SibSp Count')
plt.xlabel('SibSp')
plt.ylabel('Count')
plt.show()

"""**Remarks**: Sá»‘ ngÆ°á»i Ä‘i má»™t mÃ¬nh chiáº¿m pháº§n lá»›n."""

# Kiá»ƒm tra sá»± tÆ°Æ¡ng quan cá»§a biáº¿n Sipsb so vá»›i biáº¿n target (Survived)
sns.catplot(x='SibSp', y='Survived', data=df_copy, kind='bar')
fig=plt.gcf()
fig.set_size_inches(5,3)
plt.show()

"""**Remarks:** Nhá»¯ng ngÆ°á»i Ä‘i má»™t mÃ¬nh cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t rÆ¡i vÃ o khoáº£ng 35%. Tá»‰ lá»‡ sá»‘ng sÃ³t tÄƒng vá»›i nhá»¯ng ngÆ°á»i cÃ³ 1 Sibsp (khoáº£ng 55%), sau Ä‘Ã³ giáº£m dáº§n. Äiá»u nÃ y thá»ƒ hiá»‡n ráº±ng sá»‘ anh chá»‹ em, hoáº·c vá»£/chá»“ng Ä‘i cÅ©ng cÅ©ng lÃ  má»™t nhÃ¢n tá»‘ cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t."""

# Kiá»ƒm tra sá»± tÆ°Æ¡ng quan cá»§a biáº¿n Sipsb vÃ  biáº¿n Pclass
sns.catplot(x='SibSp', y='Pclass', data=df_copy, kind='bar')
fig=plt.gcf()
fig.set_size_inches(5,3)
plt.show()

"""**Remarks:** Nhá»¯ng hÃ nh khÃ¡ch Ä‘i cÃ¹ng tá»« 4 ngÆ°á»i thÃ¢n trá»Ÿ lÃªn Ä‘á»u ngá»“i á»Ÿ háº¡ng vÃ© 3 - Ä‘Ã£ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  háº¡ng vÃ© cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t tháº¥p nháº¥t.

### Cá»™t *Parch*
"""

# Count distinct value
df_copy['Parch'].value_counts()

# Plot for Parch
sns.countplot(x='Parch', data=df_copy)
plt.title('Parch Count')
plt.xlabel('Parch')
plt.ylabel('Count')
plt.show()

"""**Remarks:** Nhá»¯ng ngÆ°á»i Ä‘i má»™t mÃ¬nh váº«n chiáº¿m Ä‘a sá»‘."""

# Kiá»ƒm tra sá»± tÆ°Æ¡ng quan giá»¯a biáº¿n Parch vÃ  biáº¿n target (Survived)
sns.catplot(x='Parch', y='Survived', data=df_copy, kind='bar')
fig=plt.gcf()
fig.set_size_inches(5,3)
plt.show()

"""**Remarks:** TÆ°Æ¡ng tá»± vá»›i Sipsb, nhá»¯ng ngÆ°á»i
cÃ³ tá»« 1-3 parch Ä‘i cÃ¹ng cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n so vá»›i Ä‘i má»™t mÃ¬nh, tuy nhiÃªn tá»‰ lá»‡ giáº£m khi sá»‘ parch tÄƒng lÃªn.
"""

pd.crosstab(df_copy.Parch,df_copy.Pclass).style.background_gradient(cmap='summer_r')

"""**Remarks:** tÆ°Æ¡ng tá»± nhÆ° Sibsp, nhá»¯ng gia Ä‘Ã¬nh Ä‘Ã´ng ngÆ°á»i cÅ©ng náº±m á»Ÿ háº¡ng vÃ© 3.

**==> Next Action**: Cáº£ hai biáº¿n *SibSp* vÃ  *Parch* Ä‘á»u pháº£n Ã¡nh sá»‘ lÆ°á»£ng ngÆ°á»i thÃ¢n Ä‘i cÃ¹ng hÃ nh khÃ¡ch trÃªn tÃ u, cÅ©ng nhÆ° cÃ³ má»‘i tÆ°Æ¡ng quan tÆ°Æ¡ng tá»± Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t (*Survived*) vÃ  háº¡ng vÃ© (*Pclass*). Cá»¥ thá»ƒ, qua phÃ¢n tÃ­ch tÆ°Æ¡ng quan, chÃºng ta tháº¥y ráº±ng Ä‘i cÃ¹ng khoáº£ng 1-2 ngÆ°á»i thÃ¢n thÃ¬ kháº£ nÄƒng sá»‘ng sÃ³t cao hÆ¡n Ä‘i má»™t mÃ¬nh, tuy nhiÃªn sá»‘ lÆ°á»£ng thÃ nh viÃªn gia Ä‘Ã¬nh cÃ ng lá»›n thÃ¬ tá»· lá»‡ sá»‘ng sÃ³t cá»§a hÃ nh khÃ¡ch cÃ³ xu hÆ°á»›ng giáº£m, Ä‘á»“ng thá»i nhá»¯ng hÃ nh khÃ¡ch cÃ³ gia Ä‘Ã¬nh Ä‘Ã´ng ngÆ°á»i thÆ°á»ng thuá»™c nhÃ³m hÃ nh khÃ¡ch mua vÃ© háº¡ng 3. VÃ¬ váº­y, cÃ³ thá»ƒ gá»™p 2 feature nÃ y thÃ nh 1 biáº¿n tá»•ng há»£p *Family_Size*.

### Cá»™t *Fare*
"""

df_copy['Fare']

# Kiá»ƒm tra phÃ¢n phá»‘i cá»§a biáº¿n Fare
sns.histplot(df_copy['Fare'], bins=40, kde=True)
plt.title('Fare Distribution')
plt.xlabel('Fare')
plt.ylabel('Count')
plt.show()

"""**Remarks:** Ta cÃ³ thá»ƒ tháº¥y dá»¯ liá»‡u bá»‹ lá»‡ch pháº£i ráº¥t nhiá»u, cho tháº¥y ráº¥t nhiá»u ngÆ°á»i mua vÃ© ráº» vÃ  má»™t sá»‘ Ã­t ngÆ°á»i mua vÃ© ráº¥t Ä‘áº¯t."""

sns.boxplot(x=df_copy['Fare'])
plt.title('Fare Boxplot')
plt.show()

"""**Remarks:** Ta tháº¥y ráº±ng pháº§n lá»›n giÃ¡ vÃ© dao Ä‘á»™ng quanh má»©c 30, tuy nhiÃªn váº«n tá»“n táº¡i má»™t sá»‘ trÆ°á»ng há»£p chi tráº£ má»©c vÃ© ráº¥t cao, táº¡o nÃªn cÃ¡c giÃ¡ trá»‹ ngoáº¡i lai (outliers) vÃ  khiáº¿n phÃ¢n phá»‘i cá»§a Fare bá»‹ lá»‡ch pháº£i. Loáº¡i bá» outliers Ä‘á»“ng nghÄ©a vá»›i viá»‡c loáº¡i bá» nhá»¯ng thÃ´ng tin quan trá»ng liÃªn quan Ä‘áº¿n phÃ¢n táº§ng xÃ£ há»™i vÃ  kháº£ nÄƒng sá»‘ng sÃ³t cá»§a hÃ nh khÃ¡ch â€” bá»Ÿi vÃ¬ nhá»¯ng ngÆ°á»i tráº£ giÃ¡ vÃ© cao thÆ°á»ng thuá»™c háº¡ng vÃ© cao vÃ  cÃ³ tá»· lá»‡ sá»‘ng sÃ³t cao hÆ¡n. HÆ¡n ná»¯a, do táº­p dá»¯ liá»‡u Titanic chá»‰ gá»“m 891 dÃ²ng, viá»‡c loáº¡i bá» thÃªm dá»¯ liá»‡u cÃ³ thá»ƒ gÃ¢y máº¥t mÃ¡t Ä‘Ã¡ng ká»ƒ. Do Ä‘Ã³, thay vÃ¬ loáº¡i bá» outliers, ta cÃ³ thá»ƒ Ã¡p dá»¥ng ká»¹ thuáº­t binning Ä‘á»ƒ phÃ¢n loáº¡i Fare thÃ nh cÃ¡c nhÃ³m, giÃºp mÃ´ hÃ¬nh dá»… há»c hÆ¡n mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin quan trá»ng.


"""

# Kiá»ƒm tra tÆ°Æ¡ng quan cá»§a Fare vÃ  Pclass
f,ax=plt.subplots(1,3,figsize=(20,8))
sns.histplot(df[df['Pclass']==1].Fare,ax=ax[0])
ax[0].set_title('Fares in Pclass 1')
sns.histplot(df[df['Pclass']==2].Fare,ax=ax[1])
ax[1].set_title('Fares in Pclass 2')
sns.histplot(df[df['Pclass']==3].Fare,ax=ax[2])
ax[2].set_title('Fares in Pclass 3')
plt.show()

"""**Remarks**:


*   GiÃ¡ vÃ© trung bÃ¬nh cá»§a cÃ¡c háº¡ng vÃ© giáº£m dáº§n, cao nháº¥t lÃ  háº¡ng vÃ© 1, tháº¥p nháº¥t lÃ  háº¡ng vÃ© 3.
*   Háº¡ng vÃ© 1 cÃ³ giÃ¡ vÃ© Ä‘a dáº¡ng, tráº£i rá»™ng tá»« 0-500.

**Next Action**: dÃ¹ng ká»¹ thuáº­t binning Ä‘á»ƒ phÃ¢n nhÃ³m giÃ¡ vÃ©, dá»… dÃ ng cho phÃ¢n tÃ­ch vÃ  mÃ´ hÃ¬nh hoÃ¡.

## 3.3. Correlation Analysis (PhÃ¢n tÃ­ch tÆ°Æ¡ng quan)
"""

# Ma tráº­n tÆ°Æ¡ng quan cá»§a toÃ n bá»™ táº­p dá»¯ liá»‡u
# Táº¡o há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a tá»«ng Ä‘áº·c Ä‘iá»ƒm
from pandas import set_option

# Set display precision
# Set the precision for float display
set_option('display.float_format', '{:,.3f}'.format)

# Thá»±c hiá»‡n trÃªn cÃ¡c cá»™t sá»‘

# TÃ­nh ma tráº­n tÆ°Æ¡ng quan
correlation = numerical_data.corr(method='pearson')

# Biá»ƒu diá»…n ma tráº­n tÆ°Æ¡ng quan
correlation

# Plot correlation matrix in heatmap
fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(numerical_data.corr(), ax=ax, annot=True)
plt.show()

# Biá»ƒu Ä‘á»“ tÆ°Æ¡ng quan giá»¯a cÃ¡c thuá»™c tÃ­nh sá»‘ vÃ  má»¥c tiÃªu
fig, ax = plt.subplots(3,1, figsize=(12, 12))
## Há»‡ sá»‘ tÆ°Æ¡ng quan sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau
corr1 = numerical_data.corr('pearson')[['Survived']].sort_values(by='Survived', ascending=False)
corr2 = numerical_data.corr('spearman')[['Survived']].sort_values(by='Survived', ascending=False)
corr3 = numerical_data.corr('kendall')[['Survived']].sort_values(by='Survived', ascending=False)

# Äáº·t tiÃªu Ä‘á» cho tá»«ng biá»ƒu Ä‘á»“
ax[0].set_title('PhÆ°Æ¡ng phÃ¡p Pearson')
ax[1].set_title('PhÆ°Æ¡ng phÃ¡p spearman')
ax[2].set_title('PhÆ°Æ¡ng phÃ¡p Kendall')
## Táº¡o báº£n Ä‘á»“ nhiá»‡t
sns.heatmap(corr1, ax=ax[0], annot=True)
sns.heatmap(corr2, ax=ax[1], annot=True)
sns.heatmap(corr3, ax=ax[2], annot=True)

plt.show()

"""**==>** **Remarks:**
*   *Fare* (giÃ¡ vÃ©) vÃ  *Pclass* (háº¡ng vÃ©) lÃ  cÃ¡c thuá»™c tÃ­nh cÃ³ sá»± tÆ°Æ¡ng quan lá»›n Ä‘á»‘i vá»›i tá»‰ lá»‡ sá»‘ng sÃ³t, trong Ä‘Ã³ giÃ¡ vÃ© cÃ³ tÆ°Æ¡ng quan dÆ°Æ¡ng (ngÆ°á»i tráº£ tiá»n nhiá»u hÆ¡n cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n) vÃ  háº¡ng vÃ© cÃ³ tÆ°Æ¡ng quan Ã¢m (vÃ© háº¡ng cÃ ng tháº¥p cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t tháº¥p hÆ¡n).
*   *Sex* (giá»›i tÃ­nh): ná»¯ giá»›i cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n nam giá»›i.
*   *Age* (tuá»•i): tráº» em cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao.
*   *Embarked* (cáº£ng xuáº¥t phÃ¡t): máº·c dÃ¹ háº¡ng vÃ© 1 vÃ  2 cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao, tháº¿ nhÆ°ng tá»‰ lá»‡ sá»‘ng sÃ³t cá»§a nhá»¯ng hÃ nh khÃ¡ch xuáº¥t phÃ¡t tá»« cáº£ng C láº¡i cao hÆ¡n cáº£ng S - nÆ¡i cÃ³ sá»‘ lÆ°á»£ng hÃ nh khÃ¡ch Ä‘i háº¡ng vÃ© cao cáº¥p nhiá»u nháº¥t. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c lÃ½ giáº£i bá»Ÿi viá»‡c cáº£ng S cÃ³ Ä‘Ã´ng hÃ nh khÃ¡ch nháº¥t, do Ä‘Ã³ cÅ©ng cÃ³ nhiá»u hÃ nh khÃ¡ch Ä‘i háº¡ng vÃ© 3 (Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  tá»‰ lá»‡ sá»‘ng sÃ³t tháº¥p nháº¥t) hÆ¡n cáº£ng C.
*   *Parch* (sá»‘ cha máº¹/con Ä‘i cÃ¹ng) vÃ  *Sibsp* (sá»‘ anh chá»‹ em/vá»£ chá»“ng Ä‘i cÃ¹ng): nhá»¯ng hÃ nh khÃ¡ch cÃ³ tá»« 1-2 anh chá»‹ em/vá»£ chá»“ng vÃ  1-3 cha máº¹/con cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n nhá»¯ng khÃ¡ch Ä‘i má»™t mÃ¬nh hoáº·c Ä‘i cÃ¹ng gia Ä‘Ã¬nh quÃ¡ Ä‘Ã´ng.
*   CÃ¡c thuá»™c tÃ­nh cÃ²n láº¡i cÃ³ tÆ°Æ¡ng quan yáº¿u, cho tháº¥y cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng nháº¹ Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t nhÆ°ng khÃ´ng Ä‘Ã¡ng ká»ƒ.


**==> Next Action:**


*   Xá»­ lÃ½ giÃ¡ trá»‹ khuyáº¿t: Cáº§n xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ thiáº¿u á»Ÿ cá»™t *Embarked* vÃ  *Age* Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh.
*   Táº¡o Ä‘áº·c trÆ°ng má»›i (feature engineering): CÃ³ thá»ƒ káº¿t há»£p hai thuá»™c tÃ­nh *Parch* (cha máº¹/con) vÃ  *SibSp* (anh chá»‹ em/vá»£/chá»“ng) thÃ nh má»™t Ä‘áº·c trÆ°ng duy nháº¥t  pháº£n Ã¡nh má»‘i quan há»‡ gia Ä‘Ã¬nh vÃ  áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t.
*   Rá»i ráº¡c hÃ³a (binning): Cá»™t *Fare* vÃ  *Age* cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n chia thÃ nh cÃ¡c khoáº£ng (bins) Ä‘á»ƒ dá»… mÃ´ hÃ¬nh hoÃ¡.

## 3.4. Kiá»ƒm tra tÃ­nh máº¥t cÃ¢n báº±ng (imbalance) cá»§a dá»¯ liá»‡u
"""

class_counts=df_copy.groupby("Survived").size()

columns=['Survived','count','percentage']
survived=[0,1]
count=list()
percentage=list()

# TÃ­nh tá»‰ lá»‡ pháº§n trÄƒm
for val in range(2):
    count.append(class_counts[val])
    percent=(class_counts[val]/105000)*100
    percentage.append(percent)

imbalance_df=pd.DataFrame(list(zip(survived,count,percentage)),columns=columns)
imbalance_df

sns.barplot(data=imbalance_df,x=imbalance_df['Survived'],y=imbalance_df['percentage'])
plt.show()

"""**Remarks**:


*   Dá»±a trÃªn báº£ng phÃ¢n phá»‘i, khoáº£ng 52,3% máº«u cÃ³ nhÃ£n 0 vÃ  32,6% máº«u cÃ³ nhÃ£n 1. Äiá»u nÃ y cho tháº¥y cÃ³ sá»± máº¥t cÃ¢n báº±ng nháº¥t Ä‘á»‹nh giá»¯a hai lá»›p.
*   Do Ä‘Ã³, nÃªn sá»­ dá»¥ng thÃªm cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ khÃ¡c nhÆ° precision, recall, vÃ  F1-score thay vÃ¬ chá»‰ sá»­ dá»¥ng chá»‰ sá»‘ accuracy Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh má»™t cÃ¡ch toÃ n diá»‡n hÆ¡n vÃ  chÃ­nh xÃ¡c hÆ¡n.

# ğŸŸ¢ 4. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing)

##Xá»­ lÃ­ cÃ¡c giÃ¡ trá»‹ khuyáº¿t (missing values)
"""

#Cá»™t Age
df_copy[df_copy['Age'].isnull()]

# TÃ­nh mean cá»§a Age Ä‘Æ°á»£c groupby Honorific
df_copy.groupby('Honorific')['Age'].mean()

#Thay tháº¿ cÃ¡c giÃ¡ trá»‹ NaN trong cá»™t Age báº±ng Mean cá»§a Age Ä‘Æ°á»£c groupby Honorific
df_copy.loc[(df_copy['Age'].isnull())&(df_copy['Honorific'] == 'Master'),'Age'] = 5
df_copy.loc[(df_copy['Age'].isnull())&(df_copy['Honorific'] == 'Miss'),'Age'] = 22
df_copy.loc[(df_copy['Age'].isnull())&(df_copy['Honorific'] == 'Mr'),'Age'] = 33
df_copy.loc[(df_copy['Age'].isnull())&(df_copy['Honorific'] == 'Mrs'),'Age'] = 36
df_copy.loc[(df_copy['Age'].isnull())&(df_copy['Honorific'] == 'Other'),'Age'] = 46

#Double check
df_copy[df_copy['Age'].isnull()]

# Cá»™t Cabin
df_copy[df_copy['Cabin'].isnull()]
# Do dá»¯ liá»‡u cá»§a Cabin chÆ°a biáº¿t nÃªn khÃ´ng thá»ƒ thay báº±ng gÃ¬ vÃ  cá»™t Cabin cÅ©ng khÃ´ng cÃ³ tÃ¡c dá»¥ng cho viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh nÃªn khÃ´ng cáº§n pháº£i xá»­ lÃ­.

# Cá»™t Embarked
df_copy[df_copy['Embarked'].isnull()]

# Thay tháº¿ báº±ng giÃ¡ trá»‹ cá»§a Cáº£ng xuáº¥t phÃ¡t cÃ³ nhiá»u hÃ nh khÃ¡ch nháº¥t
df_copy['Embarked'] = df_copy['Embarked'].fillna('S')

# Double check
df_copy[df_copy['Embarked'].isnull()]

"""## Táº¡o Ä‘áº·c trÆ°ng má»›i (Feature Engineering)"""

# Gá»™p 2 cá»™t SipSp vÃ  Parch thÃ nh 1 cá»™t Ä‘á»ƒ thÃ nh 1 Ä‘áº·c trÆ°ng duy nháº¥t pháº£n Ã¡nh má»‘i quan há»‡ gia Ä‘Ã¬nh vÃ  áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t
df_copy['Family_Size'] = 0
df_copy['Family_Size'] = df_copy['SibSp'] + df_copy['Parch']
# Táº¡o thÃªm Ä‘áº·c trÆ°ng Alone Ä‘á»ƒ biá»ƒu thá»‹ hÃ nh khÃ¡ch cÃ³ Ä‘i má»™t mÃ¬nh hay khÃ´ng
df_copy['Alone'] = 0
df_copy.loc[df_copy.Family_Size == 0, 'Alone'] = 1

# TÆ°Æ¡ng quan giá»¯a Ä‘áº·c trÆ°ng Family_Size vÃ  Alone vá»›i Survived
f,ax=plt.subplots(1,2,figsize=(18,6))
sns.barplot(x='Family_Size',y='Survived', data=df_copy,ax=ax[0])
ax[0].set_title('Family_Size vs Survived')
sns.barplot(x='Alone',y='Survived',data=df_copy,ax=ax[1])
ax[1].set_title('Alone vs Survived')
plt.show()

"""**Remarks:**
- Náº¿u hÃ nh khÃ¡ch cÃ³ *Family_Size* = 0 (hÃ nh khÃ¡ch Ä‘i má»™t mÃ¬nh) cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t khÃ¡ tháº¥p (khoáº£ng 0.3), tá»‰ lá»‡ tÄƒng dáº§n khi *Family_Size* tÄƒng lÃªn tá»›i 3, nhÆ°ng *Family_Size* > 4 tá»‰ lá»‡ cÃ ng giáº£m dáº§n, khi *Family_Size* = 6 tá»‰ lá»‡ láº¡i tÄƒng lÃªn > 0.3.
- CÃ²n vá»›i *Alone*, hÃ nh khÃ¡ch khÃ´ng Ä‘i má»™t mÃ¬nh cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n Ä‘i má»™t mÃ¬nh.
"""

# TÆ°Æ¡ng quan giá»¯a Alone vá»›i Survived thÃ´ng qua Sex vÃ  PClass
sns.catplot( x='Alone', y='Survived',data = df_copy, hue='Sex', col='Pclass', kind='bar')
plt.show()

"""**Remarks:**
- Tá»« biá»ƒu Ä‘á»“ trÃªn, ta tháº¥y Ä‘Æ°á»£c viá»‡c Ä‘i má»™t mÃ¬nh Ä‘á»u cÃ³ tá»‰ lá»‡ sá»‘ng tháº¥p hÆ¡n báº¥t ká»ƒ Giá»›i tÃ­nh (Sex) vÃ  Háº¡ng vÃ© (Pclass) nÃ o. Ngoáº¡i trá»« háº¡ng Pclass = 3 á»Ÿ giá»›i tÃ­nh ná»¯, Ä‘i má»™t mÃ¬nh cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao hÆ¡n vÃ  Pclass = 1 á»Ÿ giá»›i tÃ­nh ná»¯, Ä‘i má»™t mÃ¬nh cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t xáº¥p xá»‰ khÃ´ng Ä‘i má»™t mÃ¬nh.

## Rá»i ráº¡c hÃ³a (binning)
"""

# Age_band
# Chia Ä‘áº·c trÆ°ng Age thÃ nh cÃ¡c khoáº£ng nhá» hÆ¡n Ä‘á»ƒ dá»… mÃ´ hÃ¬nh hÃ³a
# Do max cá»§a Age lÃ  80 nÃªn chia Age thÃ nh 5 khoáº£ng, má»—i khoáº£ng lÃ  80/5 = 16
df_copy['Age'].max()

# Táº¡o Ä‘áº·c trÆ°ng Age_band Ä‘á»ƒ chuyá»ƒn Age thÃ nh giÃ¡ trá»‹ phÃ¢n loáº¡i
# Viá»‡c gÃ¡n tá»«ng nhÃ³m tuá»•i trong Age_Band thÃ nh cÃ¡c giÃ¡ trá»‹ liÃªn tá»¥c 0, 1, 2,... lÃ  há»£p lÃ½ vÃ¬ cÃ¡c nhÃ³m tuá»•i cÃ³ tÃ­nh thá»© tá»±.
df_copy['Age_band']=0
df_copy.loc[df_copy['Age']<=16,'Age_band']=0
df_copy.loc[(df_copy['Age']>16)&(df_copy['Age']<=32),'Age_band']=1
df_copy.loc[(df_copy['Age']>32)&(df_copy['Age']<=48),'Age_band']=2
df_copy.loc[(df_copy['Age']>48)&(df_copy['Age']<=64),'Age_band']=3
df_copy.loc[df_copy['Age']>64,'Age_band']=4

df_copy['Age_band'].value_counts().sort_index().plot(kind='bar', rot=0, xlabel='Age_band',ylabel='count')

"""**Remarks**: Sá»‘ lÆ°á»£ng hÃ nh khÃ¡ch thuá»™c nhÃ³m tuá»•i 16-32 chiáº¿m sá»‘ lÆ°á»£ng lá»›n nháº¥t."""

# TÆ°Æ¡ng quan giá»¯a Age_band vÃ  Survived
sns.countplot(data=df_copy, x='Age_band', hue='Survived')
plt.title('Age_band vs Survived')
plt.xlabel('Age_band')
plt.ylabel('count')
plt.legend(title='Survived')
plt.show()

"""**Remarks**: Sá»‘ lÆ°á»£ng hÃ nh khÃ¡ch thuá»™c nhÃ³m tuá»•i 16-32 cÃ³ tá»‰ lá»‡ sá»‘ng sÃ³t cao nháº¥t."""

# TÆ°Æ¡ng quan giá»¯a Age_band vá»›i Survived thÃ´ng qua Pclass
sns.catplot(x='Age_band',y='Survived',data=df_copy,col='Pclass',kind='bar')
plt.show()

"""**Remarks:** Tá»‰ lá»‡ sá»‘ng sÃ³t giáº£m dáº§n theo Ä‘á»™ tuá»•i báº¥t ká»ƒ Háº¡ng vÃ© (Pclass) nÃ o."""

# Fare_Range
# Chia Ä‘áº·c trÆ°ng Fare thÃ nh cÃ¡c khoáº£ng nhá» hÆ¡n Ä‘á»ƒ dá»… mÃ´ hÃ¬nh hÃ³a
# Chia 5 khoáº£ng
df_copy['Fare_Range']=pd.qcut(df_copy['Fare'],4)
# TÃ­nh mean cá»§a má»—i khoáº£ng
df_copy.groupby('Fare_Range')['Survived'].mean()

# Táº¡o Ä‘áº·c trÆ°ng Fare_cat Ä‘á»ƒ chuyá»ƒn Fare thÃ nh giÃ¡ trá»‹ phÃ¢n loáº¡i
df_copy['Fare_cat']=0
df_copy.loc[df_copy['Fare']<=7.91,'Fare_cat']=0
df_copy.loc[(df_copy['Fare']>7.91)&(df_copy['Fare']<=14.454),'Fare_cat']=1
df_copy.loc[(df_copy['Fare']>14.454)&(df_copy['Fare']<=31),'Fare_cat']=2
df_copy.loc[(df_copy['Fare']>31)&(df_copy['Fare']<=513),'Fare_cat']=3

# TÆ°Æ¡ng quan giá»¯a Fare_cat vá»›i Survived thÃ´ng qua Sex
sns.catplot(x='Fare_cat',y='Survived',data=df_copy,hue='Sex',kind='bar')
plt.show()

"""**Remarks:** GiÃ¡ vÃ© cÃ ng tÄƒng thÃ¬ tá»‰ lá»‡ sá»‘ng sÃ³t cÃ ng cao á»Ÿ giá»›i tÃ­nh nam, cÃ²n á»Ÿ ná»¯ thÃ¬ giÃ¡ vÃ© tÄƒng dáº§n tá»›i nhÃ³m 2 thÃ¬ tá»‰ lá»‡ sá»‘ng sÃ³t giáº£m dáº§n, á»Ÿ giÃ¡ vÃ© cao nháº¥t tá»‰ lá»‡ sá»‘ng sÃ³t cá»§a ná»¯ váº«n cao nháº¥t.

## Chuyá»ƒn dá»¯ liá»‡u dáº¡ng string thÃ nh numeric

Äá»ƒ mÃ´ hÃ¬nh há»c mÃ¡y cÃ³ thá»ƒ xá»­ lÃ½ dá»¯ liá»‡u hiá»‡u quáº£, cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n loáº¡i nhÆ° *Sex*, *Embarked* vÃ  *Honorific* cáº§n Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh dáº¡ng sá»‘. Má»™t cÃ¡ch Ä‘Æ¡n giáº£n lÃ  gÃ¡n thá»§ cÃ´ng cÃ¡c giÃ¡ trá»‹ nÃ y thÃ nh cÃ¡c sá»‘ nhÆ° 0, 1, 2,... Tuy nhiÃªn, cÃ¡ch lÃ m nÃ y dá»… gÃ¢y hiá»ƒu nháº§m ráº±ng cÃ¡c giÃ¡ trá»‹ cÃ³ quan há»‡ thá»© báº­c, tÆ°Æ¡ng tá»± nhÆ° khi sá»­ dá»¥ng mÃ£ hoÃ¡ thá»© báº­c (ordinal encoding) â€” trong khi thá»±c táº¿, cÃ¡c giÃ¡ trá»‹ nhÆ° 'male' vÃ  'female' khÃ´ng mang tÃ­nh thá»© báº­c rÃµ rÃ ng (khÃ´ng thá»ƒ nÃ³i 'male' > 'female' hoáº·c ngÆ°á»£c láº¡i).

Äá»ƒ trÃ¡nh táº¡o ra sá»± sai lá»‡ch trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  giá»¯ nguyÃªn tÃ­nh cháº¥t phÃ¢n loáº¡i khÃ´ng thá»© báº­c cá»§a cÃ¡c Ä‘áº·c trÆ°ng nÃ y, ta sá»­ dá»¥ng ká»¹ thuáº­t one-hot encoding.

NgÆ°á»£c láº¡i, *PClass* lÃ  má»™t Ä‘áº·c trÆ°ng cÃ³ thá»© báº­c tá»± nhiÃªn (ordinal feature), nÃªn viá»‡c Ã¡p dá»¥ng ordinal encoding lÃ  há»£p lÃ½. Tuy nhiÃªn, trong dá»¯ liá»‡u gá»‘c, *PClass* Ä‘Ã£ á»Ÿ dáº¡ng sá»‘ nÃªn khÃ´ng cáº§n mÃ£ hoÃ¡ láº¡i.

TÃ³m láº¡i, ta sáº½ Ã¡p dá»¥ng one-hot encoding cho cÃ¡c cá»™t *Sex*, *Embarked* vÃ  *Honorific*.
"""

df_encoded = pd.get_dummies(df_copy, columns=['Sex', 'Embarked','Honorific'],prefix=['Sex', 'Embarked','Honorific'],dtype = int, drop_first=True)
print(df_encoded)

"""## Bá» cÃ¡c Ä‘áº·c trÆ°ng khÃ´ng cáº§n thiáº¿t

CÃ¡c Ä‘áº·c trÆ°ng nÃªn bá»:
- Name: do khÃ´ng thá»ƒ chuyá»ƒn thÃ nh dáº¡ng phÃ¢n loáº¡i nÃ o.
- Age: do Ä‘Ã£ táº¡o Ä‘áº·c trÆ°ng Age_band nÃªn khÃ´ng cáº§n Age ná»¯a.
- Ticket: do lÃ  nhá»¯ng chuá»—i kÃ½ tá»± báº¥t kÃ¬ khÃ´ng thá»ƒ phÃ¢n loáº¡i Ä‘Æ°á»£c.
- Fare: do Ä‘Ã£ cÃ³ Ä‘áº·c trÆ°ng Fare_cat nÃªn khÃ´ng cáº§n ná»¯a.
- Cabin: do cÃ³ ráº¥t nhiá»u giÃ¡ trá»‹ NaN vÃ  cÃ³ nhiá»u hÃ nh khÃ¡ch cÃ³ nhiá»u cabins khÃ¡c nhau nÃªn Ä‘áº·c trÆ°ng nÃ o khÃ´ng cÃ³ tÃ¡c dá»¥ng gÃ¬.
- Fare_Range: do Ä‘Ã£ cÃ³ Ä‘áº·c trÆ°ng Fare_cat.
- PassengerId: do khÃ´ng thá»ƒ phÃ¢n loáº¡i.
"""

# Drop these features
df_encoded.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)
df_encoded

# Plot correlation matrix in heatmap
fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(df_encoded.corr(), ax=ax, annot=True)
plt.show()

"""**Remarks:**
Tá»« biá»ƒu Ä‘á»“ tÆ°Æ¡ng quan á»Ÿ trÃªn, cÃ³ thá»ƒ tháº¥y má»™t sá»‘ Ä‘áº·c trÆ°ng cÃ³ má»‘i quan há»‡ dÆ°Æ¡ng (tÆ°Æ¡ng quan cÃ¹ng chiá»u). Má»™t vÃ i Ä‘áº·c trÆ°ng lÃ  SibSp vÃ  Family_Size, Parch vÃ  Family_Size vÃ  má»™t sá»‘ Ä‘áº·c trÆ°ng cÃ³ má»‘i quan há»‡ Ã¢m (tÆ°Æ¡ng quan ngÆ°á»£c chiá»u) nhÆ° Alone vÃ  Family_Size.

# ğŸŸ¢ 5. Modeling (MÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u)

## 5.1. PhÃ¡t triá»ƒn mÃ´ hÃ¬nh vÃ  cÃ¡c Ä‘Ã¡nh giÃ¡ cÆ¡ báº£n
"""

from sklearn.metrics import precision_recall_curve, classification_report
from sklearn.linear_model import LogisticRegression #logistic regression
from sklearn.ensemble import RandomForestClassifier #Random Forest
from sklearn import svm #support vector Machine
from sklearn.neighbors import KNeighborsClassifier #KNN
from sklearn.naive_bayes import GaussianNB #Naive bayes
from sklearn.tree import DecisionTreeClassifier #Decision Tree
from sklearn.model_selection import train_test_split #training and testing data split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""Äá»ƒ dá»± Ä‘oÃ¡n kháº£ nÄƒng sá»‘ng sÃ³t cá»§a hÃ nh khÃ¡ch, cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh sau:
1. **Logistic Regression**: lÃ  mÃ´ hÃ¬nh cÆ¡ báº£n vÃ  phá»• biáº¿n trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n, Ä‘áº·c biá»‡t lÃ  vá»›i dá»¯ liá»‡u tuyáº¿n tÃ­nh.

2. **Support Vector Machines (SVM) vá»›i kernal tuyáº¿n tÃ­nh**: phÃ¹ há»£p vá»›i dá»¯ liá»‡u phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh.

3. **Support Vector Machines (SVM) vá»›i kernal radial**: máº¡nh trong viá»‡c xá»­ lÃ½ cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i phá»©c táº¡p, Ä‘áº·c biá»‡t vá»›i kernel radial basis function (RBF), phÃ¹ há»£p khi dá»¯ liá»‡u khÃ´ng tÃ¡ch biá»‡t tuyáº¿n tÃ­nh.

4. **Random Forest**: táº­p há»£p nhiá»u cÃ¢y quyáº¿t Ä‘á»‹nh, phÃ¹ há»£p vá»›i dá»¯ liá»‡u phi tuyáº¿n.

5. **K-Nearest Neighbours (KNN)**: mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n, hoáº¡t Ä‘á»™ng tá»‘t khi dá»¯ liá»‡u cÃ³ cáº¥u trÃºc cá»¥ thá»ƒ vÃ  sá»‘ lÆ°á»£ng máº«u Ä‘á»§ lá»›n.

6. **Naive Bayes**: lÃ  mÃ´ hÃ¬nh xÃ¡c suáº¥t dá»±a trÃªn Ä‘á»‹nh lÃ½ Bayes, giáº£ Ä‘á»‹nh cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»™c láº­p vÃ  tuÃ¢n theo phÃ¢n phá»‘i xÃ¡c suáº¥t nÃ o Ä‘Ã³, hoáº¡t Ä‘á»™ng hiá»‡u quáº£ náº¿u dá»¯ liá»‡u thá»a mÃ£n nhá»¯ng giáº£ Ä‘á»‹nh vá» phÃ¢n phá»‘i hay má»‘i quan há»‡ giá»¯a biáº¿n Ä‘áº§u vÃ o vÃ  biáº¿n Ä‘áº§u ra.

7. **Decision Tree**: phÃ¹ há»£p Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c má»‘i quan há»‡ phi tuyáº¿n giá»¯a Ä‘áº·c trÆ°ng vÃ  nhÃ£n, Ä‘á»“ng thá»i dá»… trá»±c quan hÃ³a.
"""

train,test=train_test_split(df_encoded,test_size=0.2,random_state=0,stratify=df_encoded['Survived'])
train_X=train[train.columns[1:]]
train_Y=train[train.columns[:1]]
test_X=test[test.columns[1:]]
test_Y=test[test.columns[:1]]
X=df_encoded[df_encoded.columns[1:]]
Y=df_encoded['Survived']

# Logistic Regression
lr = LogisticRegression()
lr.fit(train_X, train_Y)

# Random Forest
rf = RandomForestClassifier()
rf.fit(train_X, train_Y)

#SVM (linear)
ln_svm = svm.SVC(kernel='linear')
ln_svm.fit(train_X, train_Y)

#SVM (radial)
rd_svm = svm.SVC(kernel='rbf',C=1,gamma=0.1)
rd_svm.fit(train_X,train_Y)

#KNN
knn = KNeighborsClassifier()
knn.fit(train_X, train_Y)

#Navie Bayes
nb = GaussianNB()
nb.fit(train_X, train_Y)

#Decision tree
dt = DecisionTreeClassifier()
dt.fit(train_X, train_Y)

def evaluate_model(name, model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None

    print(f"ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: {name}")
    # Ensure y_test is in the correct format (numpy array or list)
    print(f"Accuracy : {accuracy_score(y_test, y_pred):.3f}")
    print(f"Precision: {precision_score(y_test, y_pred):.3f}")
    print(f"Recall   : {recall_score(y_test, y_pred):.3f}")
    print(f"F1 Score : {f1_score(y_test, y_pred):.3f}")


# ÄÃ¡nh giÃ¡ tá»«ng mÃ´ hÃ¬nh
# Corrected variable name from X_test_scaled to test_X
evaluate_model("Logistic Regression", lr, test_X, test_Y)
evaluate_model("Random Forest", rf, test_X, test_Y)
evaluate_model("Linear SVM", ln_svm, test_X, test_Y)
evaluate_model("SVM (radial)",rd_svm, test_X, test_Y)
evaluate_model("K-Nearest Neighbors", knn, test_X, test_Y)
evaluate_model("Naive Bayes", nb, test_X, test_Y)
evaluate_model("Decision Tree", dt, test_X, test_Y)

"""VÃ¬ dá»¯ liá»‡u máº¥t cÃ¢n báº±ng (imbalance), nÃªn thay vÃ¬ chá»‰ chia táº­p dá»¯ liá»‡u thÃ nh táº­p train vÃ  táº­p test, ta sá»­ dá»¥ng *K-Fold Cross Validation*, giÃºp táº­n dá»¥ng tá»‘i Ä‘a dá»¯ liá»‡u, Ä‘á»“ng thá»i Ä‘áº£m báº£o mÃ´ hÃ¬nh Ä‘Æ°á»£c kiá»ƒm thá»­ trÃªn nhiá»u táº­p con khÃ¡c nhau, giÃºp mÃ´ hÃ¬nh khÃ´ng bá»‹ thiÃªn lá»‡ch quÃ¡ má»©c vá» lá»›p chiáº¿m Ä‘a sá»‘, nÃ¢ng cao kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a."""

from sklearn.model_selection import KFold #for K-fold cross validation
from sklearn.model_selection import cross_val_score #score evaluation
from sklearn.model_selection import cross_val_predict #prediction

kfold = KFold(n_splits=10, random_state=22, shuffle = True) # k=10, split the data into 10 equal parts
xyz=[]     ## Store the mean of accuracy of the model
accuracy=[] # Store all accuracy of a model ( kfold = 10)
std=[]
classifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']
models=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]
for i in models:
    model = i
    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = "accuracy")
    cv_result=cv_result
    xyz.append(cv_result.mean())
    std.append(cv_result.std())
    accuracy.append(cv_result)
new_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)

new_models_dataframe2

## Distribution of the accuracy of each model
plt.subplots(figsize=(12,6))
box=pd.DataFrame(accuracy,index=[classifiers])
box.T.boxplot()

"""**Remarks**:

*   Radial SVM cÃ³ trung bÃ¬nh giÃ¡ trá»‹ Accuracy cao nháº¥t, cho tháº¥y Ä‘Ã¢y lÃ  mÃ´ hÃ¬nh cÃ³ hiá»‡u suáº¥t cao nháº¥t trong sá»‘ cÃ¡c mÃ´ hÃ¬nh.
*   Logistic Regression tuy khÃ´ng cÃ³ trung bÃ¬nh cao nháº¥t, nhÆ°ng Ä‘á»™ lá»‡ch chuáº©n tháº¥p, ráº¥t á»•n Ä‘á»‹nh, cÃ³ thá»ƒ lÃ  má»™t lá»±a chá»n tá»‘t náº¿u muá»‘n mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n vÃ  dá»… giáº£i thÃ­ch.
*   Random Forest cÃ³ trung bÃ¬nh khÃ¡ cao, Ä‘á»™ lá»‡ch chuáº©n, khÃ¡ á»•n Ä‘á»‹nh.
*  Naive Bayes cÃ³ trung bÃ¬nh tháº¥p nháº¥t vÃ  Ä‘á»™ lá»‡ch chuáº©n cao nháº¥t trong táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh vÃ  cÃ³ outlier, chá»©ng tá» mÃ´ hÃ¬nh nÃ y hiá»‡u quáº£ tháº¥p, kÃ©m á»•n Ä‘á»‹nh.

**==> Next Action**: vÃ¬ dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng (imbalance), nÃªn tuy chá»‰ sá»‘ Accuracy phá»• biáº¿n, nhÆ°ng khÃ´ng pháº£n Ã¡nh Ä‘áº§y Ä‘á»§ hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh vá»›i tá»«ng lá»›p. Do Ä‘Ã³, ta xÃ©t Ä‘áº¿n cÃ¡c chá»‰ sá»‘ khÃ¡c.
"""

from sklearn.metrics import confusion_matrix

f,ax=plt.subplots(3,3,figsize=(12,10))

y_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')
ax[0,0].set_title('rbf-SVM')

y_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')
ax[0,1].set_title('Linear-SVM')

y_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')
ax[0,2].set_title('KNN')

y_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')
ax[1,0].set_title('Random-Forests')

y_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')
ax[1,1].set_title('Logistic Regression')

y_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')
ax[1,2].set_title('Decision Tree')

y_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)
sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')
ax[2,0].set_title('Naive Bayes')

plt.subplots_adjust(hspace=0.2,wspace=0.2)
plt.show()

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
y_pred_combined_dict = {}
for name, model in zip(classifiers, models):
    Y_pred_combined = cross_val_predict(model, X, Y, cv=kfold)
    print(f"ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: {name}:")
    print(classification_report(Y, Y_pred_combined, target_names=['Not Survived','Survived']))
    print('-' * 40)
    y_pred_combined_dict[name] = Y_pred_combined

"""###**TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh**

ÄÃ¢y lÃ  táº­p dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng sá»‘ng sÃ³t cá»§a má»™t hÃ nh khÃ¡ch nÃ o Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ há»— trá»£ cá»©u há»™, phÃ¢n bá»• nguá»“n lá»±c cá»©u ngÆ°á»i. Do Ä‘Ã³, cáº§n chÃº Ã½ cÃ¡c chá»‰ sá»‘ sau Ä‘Ã¢y:

1.  **Recall cá»§a lá»›p 'Survived'**: Ä‘Ã¢y lÃ  tá»· lá»‡ ngÆ°á»i thá»±c sá»± sá»‘ng sÃ³t mÃ  mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng. Trong bá»‘i cáº£nh cá»©u há»™, viá»‡c bá» sÃ³t ngÆ°á»i sá»‘ng (dá»± Ä‘oÃ¡n lÃ  cháº¿t trong khi thá»±c táº¿ cÃ²n sá»‘ng â€“ sai láº§m loáº¡i 2) lÃ  nghiÃªm trá»ng hÆ¡n so vá»›i viá»‡c dá»± Ä‘oÃ¡n nháº§m ngÆ°á»i cháº¿t lÃ  sá»‘ng (sai láº§m loáº¡i 1). Do Ä‘Ã³, cáº§n Æ°u tiÃªn tá»‘i thiá»ƒu hÃ³a False Negative, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c tá»‘i Ä‘a hÃ³a Recall cá»§a lá»›p 'Survived'.

2.  **F1-Score cá»§a lá»›p 'Survived'**: vÃ¬ lá»›p 'Survived' lÃ  lá»›p quan trá»ng, chá»‰ sá»‘ nÃ y giÃºp cÃ¢n báº±ng vá»«a khÃ´ng bá» sÃ³t ngÆ°á»i sá»‘ng, vá»«a trÃ¡nh cáº£nh bÃ¡o sai (Ä‘oÃ¡n nháº§m ngÆ°á»i cháº¿t thÃ nh ngÆ°á»i sá»‘ng) quÃ¡ nhiá»u. ÄÃ¢y lÃ  chá»‰ sá»‘ quan trá»ng khi cáº§n kiá»ƒm soÃ¡t cáº£ hai loáº¡i sai láº§m.

3.  **Weighted F1-Score**: lÃ  trung bÃ¬nh F1-score cÃ³ trá»ng sá»‘ theo sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng lá»›p. Chá»‰ sá»‘ nÃ y cung cáº¥p má»™t cÃ¡i nhÃ¬n tá»•ng thá»ƒ vá» mÃ´ hÃ¬nh, Ä‘áº·c biá»‡t há»¯u Ã­ch khi so sÃ¡nh nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau.

###**ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh**

1. Recall cá»§a lá»›p 'Survived' : Naive Bayes cao nháº¥t vá»›i 77%, nghÄ©a lÃ  mÃ´ hÃ¬nh bá» sÃ³t Ã­t nháº¥t cÃ¡c trÆ°á»ng há»£p thá»±c sá»± sá»‘ng sÃ³t. Theo sau lÃ  Logistic Regression (74%) vÃ  Radial SVM (73%).

3. F1-Score cá»§a lá»›p 'Survived': Radial SVM cÃ³ F1-score cao nháº¥t cho Survived (0.77), cho tháº¥y sá»± cÃ¢n báº±ng tá»‘t giá»¯a precision vÃ  recall.

4. Weighted Average F1-Score
- Radial SVM cÃ³ chá»‰ sá»‘ Weighted Average F1-Score cao nháº¥t (0.83), chá»©ng tá» mÃ´ hÃ¬nh cÃ³ hiá»‡u suáº¥t tá»‘t tá»•ng thá»ƒ trÃªn cáº£ 2 lá»›p.
- NgÆ°á»£c láº¡i, Naive Bayes cÃ³ chá»‰ sá»‘ nÃ y tháº¥p nháº¥t.

**===> Vá» tá»•ng thá»ƒ**: káº¿t há»£p giá»¯a pháº§n Ä‘Ã¡nh giÃ¡ chá»‰ sá»‘ Accuracy phÃ­a trÃªn vÃ  cÃ¡c chá»‰ sá»‘ vá»«a Ä‘Ã¡nh giÃ¡
*   Radial SVM lÃ  mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng hiá»‡u quáº£ nháº¥t, cÃ¢n báº±ng tá»‘t giá»¯a Recall vÃ  Precision cho lá»›p quan trá»ng (Survived), Ä‘á»“ng thá»i Ä‘áº¡t hiá»‡u suáº¥t cao tá»•ng thá»ƒ, nhÆ°ng tá»‘n thá»i gian huáº¥n luyá»‡n, cÃ³ thá»ƒ cáº§n hiá»‡u chá»‰nh siÃªu tham sá»‘.
*   Logistic Regression tuy Ä‘Æ¡n giáº£n nhÆ°ng khÃ¡ á»•n Ä‘á»‹nh.
*   Naive Bayes tuy phÃ¡t hiá»‡n nhiá»u ngÆ°á»i sá»‘ng (Recall cho lá»›p 'Survived' cao) nhÆ°ng hiá»‡u suáº¥t tá»•ng thá»ƒ khÃ´ng Ä‘Ã¡ng tin cáº­y.

###==> **Äá» xuáº¥t cáº£i tiáº¿n mÃ´ hÃ¬nh:**

1. Hyper-parameters Tuning (Hiá»‡u chá»‰nh siÃªu tham sá»‘)
2. Ensemble: káº¿t há»£p cÃ¡c  mÃ´ hÃ¬nh láº¡i Ä‘á»ƒ táº¡o ra mÃ´ hÃ¬nh máº¡nh hÆ¡n, giáº£m sai sá»‘, tÄƒng Ä‘á»™ chÃ­nh xÃ¡c

## 5.2. Tá»‘i Æ°u hÃ³a vÃ  cáº£i tiáº¿n mÃ´ hÃ¬nh

### 5.2.1. Hyper Parameter Tuning (Hiá»‡u chá»‰nh siÃªu tham sá»‘)

Hiá»‡u chá»‰nh siÃªu tham sá»‘ cho mÃ´ hÃ¬nh Radial SVM - mÃ´ hÃ¬nh thá»ƒ hiá»‡n tiá»m nÄƒng cao nháº¥t trong nhá»¯ng bÆ°á»›c Ä‘Ã¡nh giÃ¡ trÃªn.

Radial SVM cÃ³ cÃ¡c siÃªu tham sá»‘:
*  C: Ä‘iá»u chá»‰nh Ä‘á»™ pháº¡t Ä‘á»‘i vá»›i sai sá»‘ (giá»¯a underfitting vÃ  overfitting).
*   gamma: xÃ¡c Ä‘á»‹nh pháº¡m vi áº£nh hÆ°á»Ÿng cá»§a má»™t Ä‘iá»ƒm dá»¯ liá»‡u.
"""

from sklearn.model_selection import GridSearchCV

C=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1] # Ä‘iá»u khiá»ƒn Ä‘á»™ pháº¡t Ä‘á»‘i vá»›i sai sá»‘ (Ä‘á»™ pháº¡t cÃ ng lá»›n thÃ¬ mÃ´ hÃ¬nh cÃ ng dá»… overfit)
gamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0] # Ä‘iá»u khiá»ƒn Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a má»™t Ä‘iá»ƒm máº«u (nhá» thÃ¬ áº£nh hÆ°á»Ÿng rá»™ng, Ã­t bá»‹ overfit; lá»›n thÃ¬ áº£nh hÆ°á»Ÿng cá»¥c bá»™ hÆ¡n, dá»… overfit)
kernel=['rbf'] # Chá»‰ tuning trÃªn kernel RBF (Radial SVM)
hyper={'kernel':kernel,'C':C,'gamma':gamma}
gd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,cv=10,verbose=True)
gd.fit(X,Y)
print(gd.best_score_)
print(gd.best_estimator_)

"""**Remarks**:


*   MÃ´ hÃ¬nh Radial SVM hoáº¡t Ä‘á»™ng tá»‘t nháº¥t khi C=0.9 vÃ  gamma=0.2 trÃªn táº­p dá»¯ liá»‡u nÃ y vá»›i k = 10 trong K-Fold Cross Validation.
*   Accuracy trung bÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c lÃ  83,05%.

==> Viá»‡c tuning khÃ´ng mang láº¡i cáº£i thiá»‡n lá»›n, nhÆ°ng cho tháº¥y mÃ´ hÃ¬nh ban Ä‘áº§u Ä‘Ã£ hoáº¡t Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh.

### 5.2.2. Ensembling

Ensembling lÃ  ká»¹ thuáº­t káº¿t há»£p nhiá»u mÃ´ hÃ¬nh con thÃ nh má»™t mÃ´ hÃ¬nh tá»•ng Ä‘á»ƒ tÄƒng tÃ­nh á»•n Ä‘á»‹nh vÃ  chÃ­nh xÃ¡c. 2 ká»¹ thuáº­t Ensembling Ä‘Æ¡n giáº£n nháº¥t lÃ :


*   **Voting Classifier**: káº¿t há»£p dá»± Ä‘oÃ¡n cá»§a nhiá»u mÃ´ hÃ¬nh phÃ¢n loáº¡i khÃ¡c nhau. MÃ´ hÃ¬nh tá»•ng sáº½ chá»n nhÃ£n Ä‘Æ°á»£c bá» phiáº¿u nhiá»u nháº¥t (majority voting) hoáº·c tÃ­nh trung bÃ¬nh xÃ¡c suáº¥t dá»± Ä‘oÃ¡n (soft voting) Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng.
*   **Bagging (Bootstrap Aggregating)**: tá»« táº­p dá»¯ liá»‡u ban Ä‘áº§u, táº¡o ra nhiá»u táº­p dá»¯ liá»‡u con khÃ¡c nhau báº±ng cÃ¡ch láº¥y máº«u ngáº«u nhiÃªn cÃ³ láº·p (bootstrap sampling), sau Ä‘Ã³ Ã¡p dÃ¹ng cÃ¹ng mÃ´ hÃ¬nh lÃªn tá»«ng táº­p con Ä‘Ã³, cuá»‘i cÃ¹ng bá» phiáº¿u chá»n nhÃ£n (majority voting).

#### Voting Classifier

Tá»« má»¥c tiÃªu Æ°u tiÃªn recall cá»§a lá»›p "Survived", nhÃ³m Ä‘á» xuáº¥t sá»­ dá»¥ng Soft Voting Ä‘á»ƒ káº¿t há»£p cÃ¡c mÃ´ hÃ¬nh sau:

*   Radial SVM: lÃ  mÃ´ hÃ¬nh cho hiá»‡u suáº¥t tá»•ng thá»ƒ tá»‘t nháº¥t trÃªn táº­p kiá»ƒm tra.\
*   Naive Bayes: Ä‘áº¡t recall cao nháº¥t Ä‘á»‘i vá»›i lá»›p "Survived", phÃ¹ há»£p vá»›i má»¥c tiÃªu cá»§a bÃ i toÃ¡n.
*   Random Forest: lÃ  mÃ´ hÃ¬nh tá»• há»£p máº¡nh, cÃ³ kháº£ nÄƒng xá»­ lÃ½ quan há»‡ phi tuyáº¿n.

Viá»‡c sá»­ dá»¥ng Soft Voting cho phÃ©p táº­n dá»¥ng xÃ¡c suáº¥t dá»± Ä‘oÃ¡n cá»§a tá»«ng mÃ´ hÃ¬nh, tá»« Ä‘Ã³ cáº£i thiá»‡n kháº£ nÄƒng phÃ¡t hiá»‡n Ä‘Ãºng cÃ¡c trÆ°á»ng há»£p thuá»™c lá»›p "Survived", thay vÃ¬ chá»‰ dá»±a trÃªn Ä‘a sá»‘ phiáº¿u nhÆ° Majority Voting. Äiá»u nÃ y Ä‘áº·c biá»‡t quan trá»ng khi cÃ¡c mÃ´ hÃ¬nh cÃ³ Ä‘á»™ máº¡nh khÃ¡c nhau vÃ  khi bÃ i toÃ¡n Æ°u tiÃªn giáº£m bá» sÃ³t (false negatives).
"""

from sklearn.ensemble import VotingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

# CÃ¡c mÃ´ hÃ¬nh lá»±a chá»n Ä‘á»ƒ ensemble
clf1 = SVC(kernel='rbf', C=1, gamma=0.1, probability=True) # Radial SVM, probability=True Ä‘á»ƒ sá»­ dá»¥ng soft voting vÃ¬ Radial SVM khÃ´ng tráº£ vá» xÃ¡c suáº¥t
clf2 = GaussianNB() # Naive Bayes
clf3 = RandomForestClassifier(n_estimators=100, random_state=1) # Random Forest

# Voting Classifier
eclf1 = VotingClassifier(estimators=[('svm', clf1), ('gnb', clf2), ('rf', clf3)], voting='soft', weights=[1, 1, 1])

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
cv_result_ensemble = cross_val_score(eclf1, X, Y, cv=kfold, scoring="accuracy")
print(f"ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: Soft Voting (Radial SVM, Naive Bayes, Random Forest)")
print(f"CV Mean Accuracy: {cv_result_ensemble.mean():.3f}")
print(f"CV Accuracy Standard Deviation: {cv_result_ensemble.std():.3f}")

y_pred_ensemble = cross_val_predict(eclf1, X, Y, cv=kfold)

print(classification_report(Y, y_pred_ensemble, target_names=['Not Survived', 'Survived']))

# Confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(Y, y_pred_ensemble), annot=True, fmt='2.0f')
plt.title('Soft Voting Ensemble Confusion Matrix')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.show()

"""**Remarks**:
So vá»›i tá»«ng mÃ´ hÃ¬nh, Soft Voting khai thÃ¡c Ä‘Æ°á»£c tháº¿ máº¡nh cá»§a tá»«ng mÃ´ hÃ¬nh tuy nhiÃªn sá»± cáº£i thiá»‡n nhÆ°ng khÃ´ng Ä‘Ã¡ng ká»ƒ tháº­m chÃ­ cÃ¡c chá»‰ sá»‘, tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ bá»‹ giáº£m nháº¹.

==> Viá»‡c soft voting khÃ´ng mang láº¡i cáº£i thiá»‡n hiá»‡u quáº£, nhÆ°ng cho tháº¥y mÃ´ hÃ¬nh ban Ä‘áº§u Ä‘Ã£ hoáº¡t Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh.

#### Bagging

Bagging giÃºp giáº£m phÆ°Æ¡ng sai cá»§a mÃ´ hÃ¬nh, nÃªn hiá»‡u quáº£ nháº¥t khi Ã¡p dá»¥ng vá»›i cÃ¡c mÃ´ hÃ¬nh cÃ³ phÆ°Æ¡ng sai cao. Do Ä‘Ã³, nhÃ³m lá»±a chá»n sá»­ dá»¥ng Bagging vá»›i cÃ¡c mÃ´ hÃ¬nh sau:
*   **K-Nearest Neighbor**: nháº¡y cáº£m vá»›i nhiá»…u vÃ  dá»¯ liá»‡u cá»¥ thá»ƒ, Bagging giÃºp tÄƒng Ä‘á»™ á»•n Ä‘á»‹nh.
*   **Decision Tree**: dá»… bá»‹ overfit vÃ  dao Ä‘á»™ng lá»›n, Bagging giÃºp giáº£m sá»± biáº¿n Ä‘á»™ng nÃ y.
*   **Random Forest**: lÃ  má»™t ká»¹ thuáº­t dá»±a trÃªn Bagging vÃ  chá»n ngáº«u nhiÃªn Ä‘áº·c trÆ°ng, giÃºp tÄƒng cÆ°á»ng tÃ­nh Ä‘a dáº¡ng vÃ  á»•n Ä‘á»‹nh cho cÃ¡c cÃ¢y quyáº¿t Ä‘á»‹nh.
"""

from sklearn.ensemble import BaggingClassifier
# Define the base estimators for bagging
# Using KNeighborsClassifier, DecisionTreeClassifier, and RandomForestClassifier
knn_bagged = KNeighborsClassifier()
dt_bagged = DecisionTreeClassifier()
rf_bagged = RandomForestClassifier(n_estimators=100, random_state=1)

# Create Bagging Classifiers for each base estimator
# Changed base_estimator to estimator
bagged_knn = BaggingClassifier(estimator=knn_bagged, n_estimators=10, random_state=1)
bagged_dt = BaggingClassifier(estimator=dt_bagged, n_estimators=10, random_state=1)
bagged_rf = BaggingClassifier(estimator=rf_bagged, n_estimators=10, random_state=1)

# Evaluate each Bagging Classifier using cross-validation
bagged_knn_cv = cross_val_score(bagged_knn, X, Y, cv=kfold, scoring="accuracy")
bagged_dt_cv = cross_val_score(bagged_dt, X, Y, cv=kfold, scoring="accuracy")
bagged_rf_cv = cross_val_score(bagged_rf, X, Y, cv=kfold, scoring="accuracy")

print("ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Bagging:")
print(f"Bagged KNN CV Mean Accuracy: {bagged_knn_cv.mean():.3f}")
print(f"Bagged Decision Tree CV Mean Accuracy: {bagged_dt_cv.mean():.3f}")
print(f"Bagged Random Forest CV Mean Accuracy: {bagged_rf_cv.mean():.3f}")

# Get cross-validated predictions and print classification reports for each bagging model
y_pred_bagged_knn = cross_val_predict(bagged_knn, X, Y, cv=kfold)
print("\nğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: Bagged KNN")
print(classification_report(Y, y_pred_bagged_knn, target_names=['Not Survived', 'Survived']))
print('-' * 40)

y_pred_bagged_dt = cross_val_predict(bagged_dt, X, Y, cv=kfold)
print("\nğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: Bagged Decision Tree")
print(classification_report(Y, y_pred_bagged_dt, target_names=['Not Survived', 'Survived']))
print('-' * 40)

y_pred_bagged_rf = cross_val_predict(bagged_rf, X, Y, cv=kfold)
print("\nğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: Bagged Random Forest")
print(classification_report(Y, y_pred_bagged_rf, target_names=['Not Survived', 'Survived']))
print('-' * 40)

"""**Remarks**:

* MÃ´ hÃ¬nh Bagged KNN: viá»‡c bagging khÃ´ng hiá»‡u quáº£ khi cÃ¡c tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ Ä‘á»u giáº£m, Ä‘áº·c biá»‡t lÃ  recall cá»§a lá»›p Survived --> Ä‘i ngÆ°á»£c vá»›i má»¥c tiÃªu ban Ä‘áº§u lÃ  tÄƒng recall
* MÃ´ hÃ¬nh Bagged Random Forest vÃ  Bagged Decision Tree: cáº£ 2 mÃ´ hÃ¬nh nÃ y Ä‘áº¡t hiá»‡u quáº£ nhÆ° mong Ä‘á»£i sau khi bagging, cÃ¡c chá»‰ sá»‘, tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ Ä‘á»u giá»¯ á»•n Ä‘á»‹nh, hoáº·c tÄƒng, tuy nhiÃªn cÅ©ng khÃ´ng cÃ³ sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ so vá»›i mÃ´ hÃ¬nh ban Ä‘áº§u.

==> Bagging hoáº¡t Ä‘á»™ng tá»‘t vá»›i cÃ¡c mÃ´ hÃ¬nh cÃ³ phÆ°Æ¡ng sai lá»›n hÆ¡n, dao Ä‘á»™ng hÆ¡n, phá»¥ thuá»™c vÃ o tÃ­nh Ä‘a dáº¡ng vÃ  cháº¥t lÆ°á»£ng cá»§a cÃ¡c mÃ´ hÃ¬nh con. Viá»‡c bagging cho mÃ´ hÃ¬nh khÃ´ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ, Ä‘iá»u nÃ y cÃ³ thá»ƒ xuáº¥t phÃ¡t tá»« viá»‡c mÃ´ hÃ¬nh ban Ä‘áº§u Ä‘Ã£ hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.

###Feature Importance

ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ quan trá»ng cá»§a cÃ¡c thuá»™c tÃ­nh Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh
"""

import matplotlib.pyplot as plt
import pandas as pd
f, ax = plt.subplots(1, 3, figsize=(18, 12))
# Random Forest
model = RandomForestClassifier(n_estimators=500, random_state=0)
model.fit(X, Y)
# Truy cáº­p Axes Ä‘áº§u tiÃªn báº±ng index 0
pd.Series(model.feature_importances_, X.columns).sort_values(ascending=True).plot.barh(
    width=0.8, ax=ax[0])
ax[0].set_title('Feature Importance - Random Forest')

# Decision Tree
model = DecisionTreeClassifier(random_state=0)
model.fit(X, Y)
# Truy cáº­p Axes thá»© hai báº±ng index 1
pd.Series(model.feature_importances_, X.columns).sort_values(ascending=True).plot.barh(
    width=0.8, ax=ax[1], color='lightgreen')
ax[1].set_title('Feature Importance - Decision Tree')

# Logistic Regression (dÃ¹ng trá»‹ tuyá»‡t Ä‘á»‘i cá»§a há»‡ sá»‘)
model = LogisticRegression(max_iter=1000)
model.fit(X, Y)
importance = pd.Series(abs(model.coef_[0]), X.columns).sort_values(ascending=True)
# Truy cáº­p Axes thá»© ba báº±ng index 2
importance.plot.barh(width=0.8, ax=ax[2], color='lightblue')
ax[2].set_title('Feature Importance - Logistic Regression')

plt.tight_layout()
plt.show()

"""**REMARKS**

Tá»« Ä‘Ã¡nh giÃ¡ má»™t sá»‘ Ä‘áº·c trÆ°ng quan trá»ng trong cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i nhÆ° Logistic Regression, Random Forests vÃ  Decision Tree, nhÃ³m rÃºt ra má»™t sá»‘ káº¿t luáº­n má»Ÿ rá»™ng nhÆ° sau:
1. Má»™t sá»‘ Ä‘áº·c trÆ°ng quan trá»ng phá»• biáº¿n áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n káº¿t quáº£ mÃ´ hÃ¬nh lÃ : Honorific_Mr, Sex_male, Pclass, Fare_cat, Age_band vÃ  Family_size
2. ÄÃ¡ng chÃº Ã½, biáº¿n Honorific_Mr náº±m vá»‹ trÃ­ Ä‘áº§u báº£ng trong cáº£ 3 mÃ´ hÃ¬nh. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c lÃ½ giáº£i bá»Ÿi sá»‘ lÆ°á»£ng hÃ nh khÃ¡ch lÃ  nam chiáº¿m pháº§n lá»›n. Do Ä‘Ã³, máº·c dÃ¹ biáº¿n giá»›i tÃ­nh khÃ´ng náº±m vá»‹ trÃ­ hÃ ng Ä‘áº§u, nhÆ°ng thÃ´ng qua cÃ¡c biáº¿n danh xÆ°ng, má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p quan trá»ng cá»§a yáº¿u tá»‘ giá»›i tÃ­nh váº«n Ä‘Æ°á»£c thá»ƒ hiá»‡n rÃµ trong cÃ¡c mÃ´ hÃ¬nh.
3. TÆ°Æ¡ng tá»±, Pclass vÃ  Fare_cat thá»ƒ hiá»‡n Ä‘á»‹a vá»‹ cá»§a hÃ nh khÃ¡ch (áº£nh hÆ°á»Ÿng tá»›i tá»· lá»‡ sá»‘ng sÃ³t) vÃ  Age_band cÅ©ng Ä‘Ã³ng vai trÃ² khÃ´ng kÃ©m pháº§n quan trá»ng tá»›i tá»· lá»‡ sá»‘ng sÃ³t cá»§a hÃ nh khÃ¡ch vÃ   Family_Size, SibSp, Parch, Alone Ä‘á»u cÃ³ liÃªn quan Ä‘áº¿n nhau vÃ¬ váº­y Æ°u tiÃªn Family_size Ä‘á»ƒ trÃ¡nh Ä‘a cá»™ng tuyáº¿n.

# ğŸŸ¢ 6. Káº¾T LUáº¬N

* **Tá»•ng quan**: sau khi thá»­ nhiá»u kÄ© thuáº­t cáº£i thiá»‡n mÃ´ hÃ¬nh khÃ¡c nhau, nhÃ³m nháº­n tháº¥y ráº±ng táº¥t cáº£ mÃ´ hÃ¬nh Ä‘á»u hoáº¡t Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh. Viá»‡c Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t cáº£i tiáº¿n (Hyper Parameter Tuning vÃ  Ensembling) trong trÆ°á»ng há»£p nÃ y khÃ´ng mang láº¡i cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u suáº¥t.

* **CÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ phÃ¢n loáº¡i**: Ngay tá»« quÃ¡ trÃ¬nh EDA Ä‘áº¿n tiá»n xá»­ lÃ½ dá»¯ liá»‡u, nhÃ³m Ä‘Ã£ phÃ¢n tÃ­ch tá»«ng thuá»™c tÃ­nh, vÃ  xÃ¡c Ä‘á»‹nh nhá»¯ng má»‘i tÆ°Æ¡ng quan cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ phÃ¢n loáº¡i cÅ©ng nhÆ° thÃªm/bá»›t cÃ¡c feature Ä‘á»ƒ tÄƒng hiá»‡u quáº£ cho mÃ´ hÃ¬nh.

--> Káº¿t quáº£ cho tháº¥y ráº±ng cÃ¡c features Ä‘á»u hoáº¡t Ä‘á»™ng tá»‘t vá»›i vai trÃ² cá»§a mÃ¬nh, Ä‘áº·c biá»‡t cÃ¡c features Ä‘Æ°á»£c thÃªm vÃ o nhÆ° Honorific (nÃ³i chung), Family_size, Age_band cÃ³ táº§m áº£nh hÆ°á»Ÿng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n káº¿t quáº£ phÃ¢n loáº¡i, pháº£n Ã¡nh Ä‘Ãºng thá»±c táº¿.

* **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh**: Radial SVM ná»•i báº­t nháº¥t vá» tÃ­nh hiá»‡u quáº£ vÃ  Ä‘á»™ á»•n Ä‘á»‹nh. Trong khi Ä‘Ã³, Logistic Regression, dÃ¹ lÃ  mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n, váº«n cÃ³ hiá»‡u suáº¥t khÃ¡ tá»‘t.

--> Æ¯u tiÃªn sá»­ dá»¥ng 2 mÃ´ hÃ¬nh nÃ y Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n.

**HÆ°á»›ng má»Ÿ rá»™ng**:


*   Khai thÃ¡c mÃ´ hÃ¬nh nÃ¢ng cao hÆ¡n: Thá»­ nghiá»‡m vá»›i cÃ¡c mÃ´ hÃ¬nh máº¡nh hÆ¡n nhÆ° XGBoost, LightGBM, hoáº·c mÃ´ hÃ¬nh deep learning náº¿u cÃ³ Ä‘á»§ dá»¯ liá»‡u vÃ  tÃ i nguyÃªn.
*   Xem xÃ©t kháº£ nÄƒng triá»ƒn khai thá»±c táº¿: giáº£ Ä‘á»‹nh náº¿u cÃ³ tai náº¡n tÃ u hiá»‡n Ä‘áº¡i, cáº§n xem xÃ©t liá»‡u mÃ´ hÃ¬nh hiá»‡n táº¡i cÃ²n phÃ¹ há»£p khÃ´ng. Viá»‡c nÃ y Ä‘Ã²i há»i bá»• sung thÃªm cÃ¡c features Ä‘áº§u vÃ o (vÃ­ dá»¥ nhÆ° loáº¡i tÃ u, há»‡ thá»‘ng Ä‘iá»u khiá»ƒn, dá»¯ liá»‡u cáº£m biáº¿n thá»i gian thá»±c,...) vÃ  thÆ°á»ng xuyÃªn cáº­p nháº­t vÃ  tÃ¡i huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»ƒ Ä‘áº£m báº£o kháº£ nÄƒng thÃ­ch á»©ng vá»›i nhá»¯ng thay Ä‘á»•i trong thá»±c táº¿.



**Káº¿t luáº­n**: Qua quÃ¡ trÃ¬nh xÃ¢y dá»±ng, cáº£i tiáº¿n vÃ  phÃ¢n tÃ­ch, nhÃ³m khÃ´ng chá»‰ rÃºt ra Ä‘Æ°á»£c mÃ´ hÃ¬nh phÃ¹ há»£p mÃ  cÃ²n hiá»ƒu rÃµ hÆ¡n vá» dá»¯ liá»‡u vÃ  nhá»¯ng yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ phÃ¢n loáº¡i. DÃ¹ mÃ´ hÃ¬nh chÆ°a Ä‘áº¡t Ä‘Æ°á»£c sá»± cáº£i thiá»‡n vÆ°á»£t trá»™i tá»« cÃ¡c ká»¹ thuáº­t nÃ¢ng cao, nhÆ°ng Ä‘iá»u Ä‘Ã³ cÅ©ng cho tháº¥y ráº±ng cÃ¡c bÆ°á»›c xá»­ lÃ½ ban Ä‘áº§u vÃ  lá»±a chá»n mÃ´ hÃ¬nh cÆ¡ báº£n cá»§a nhÃ³m Ä‘Ã£ khÃ¡ há»£p lÃ½ vÃ  hiá»‡u quáº£. ÄÃ¢y lÃ  tiá»n Ä‘á» tá»‘t Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c bÃ i toÃ¡n phÃ¢n tÃ­ch tÆ°Æ¡ng tá»± trong tÆ°Æ¡ng lai.
"""